{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "This notebook contains a simple variational autoencoder. \n",
    "\n",
    "The following resources have been helpful:\n",
    "* https://arxiv.org/pdf/1606.05908v2.pdf\n",
    "* https://jmetzen.github.io/2015-11-27/vae.html\n",
    "_______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load CIFAR data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import cifar10_input\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Functions from \n",
    "   github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10.py\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Basic model parameters.\n",
    "BATCH_SIZE = 6\n",
    "DATA_DIR = '/media/data/Dropbox/Git/dreamscape/data/cifar10'\n",
    "USE_FP16 = False\n",
    "\n",
    "# Global constants describing the CIFAR-10 data set.\n",
    "IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "NUM_CLASSES = cifar10_input.NUM_CLASSES\n",
    "\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "def maybe_download_and_extract():\n",
    "    \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "    \n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    \n",
    "    extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "\n",
    "def inputs(eval_data):\n",
    "    \"\"\"Construct input for CIFAR evaluation using the Reader ops.\n",
    "    Args:\n",
    "        eval_data: bool, indicating if one should use the train or eval data set.\n",
    "    Returns:\n",
    "        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n",
    "        labels: Labels. 1D tensor of [batch_size] size.\n",
    "    Raises:\n",
    "        ValueError: If no data_dir\n",
    "    \"\"\"\n",
    "    \n",
    "    if not DATA_DIR:\n",
    "        raise ValueError('Please supply a data_dir')\n",
    "    data_dir = os.path.join(DATA_DIR, 'cifar-10-batches-bin')\n",
    "    images, labels = cifar10_input.inputs(eval_data=eval_data,\n",
    "                                          data_dir=data_dir,\n",
    "                                          batch_size=BATCH_SIZE)\n",
    "    if USE_FP16:\n",
    "        images = tf.cast(images, tf.float16)\n",
    "        labels = tf.cast(labels, tf.float16)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# download data if not present\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 2500 CIFAR images before starting to train. This will take a few minutes.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "[images, labels] = inputs(False)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print(type(labels))\n",
    "print(labels[0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = sess.run(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.variables.Variable'>\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "test = tf.Variable([1,2,3])\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "print(type(test))\n",
    "print(test.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VAE(object):\n",
    "    \"\"\" Variational Autoencoder class \"\"\"\n",
    "    \n",
    "    def __init__(self, layers_encoder=None, layer_latent=None, layers_decoder=None, \n",
    "                 act_func=tf.nn.relu, batch_size=100, learning_rate=1e-3):\n",
    "        \"\"\" Constructor for VAE class \"\"\"\n",
    "        \n",
    "        assert layers_encoder, \"Must specify layer sizes for encoder\"\n",
    "        assert layer_latent, \"Must specify number of latent dimensions\"\n",
    "        assert layers_decoder, \"Must specify layer sizes for decoder\"\n",
    "        self.layers_encoder = layers_encoder\n",
    "        self.layer_latent = layer_latent\n",
    "        self.layers_decoder = layers_decoder\n",
    "        self.layers_decoder.insert(0, layer_latent) # helps with weight init later\n",
    "        \n",
    "        self.act_func = act_func\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # define useful constants\n",
    "        self.num_lvs = self.layer_latent\n",
    "        self.num_layers_enc = len(self.layers_encoder)\n",
    "        self.num_layers_dec = len(self.layers_decoder)\n",
    "        \n",
    "        # for saving and restoring models\n",
    "        self.graph = tf.Graph() # must be initialized before graph creation\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            # create placeholders for input and random values\n",
    "            self.x = tf.placeholder(tf.float32, shape=[None, self.layers_encoder[0]])\n",
    "            self.eps = tf.placeholder(tf.float32, shape=[None, self.num_lvs])\n",
    "            \n",
    "            # initialize weights and create model\n",
    "            self._initialize_weights()\n",
    "            self._define_recognition_network()\n",
    "            self._define_generator_network()\n",
    "            self._define_loss_optimizer()\n",
    "\n",
    "            # add additional ops\n",
    "            # for saving and restoring models\n",
    "            self.saver = tf.train.Saver() # must be initialized after var creation\n",
    "            # add variable initialization op to graph\n",
    "            self.init = tf.initialize_all_variables()\n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_variable(shape, name='None'):\n",
    "        \"\"\" Utility method to clean up initialization \"\"\"\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_variable(shape, name='None'):\n",
    "        \"\"\" Utility method to clean up initialization \"\"\"\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "        return tf.Variable(initial, name=name)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\" Initialize weights and biases in model \"\"\"\n",
    "\n",
    "        # initialize weights and biases in encoding model\n",
    "        self.weights_enc = []\n",
    "        self.biases_enc = []\n",
    "        for i in range(self.num_layers_enc-1):\n",
    "            self.weights_enc.append(self.weight_variable([self.layers_encoder[i], \n",
    "                                                          self.layers_encoder[i+1]],\n",
    "                                                         name=str('weights_enc_%02i' % i)))\n",
    "            self.biases_enc.append(self.bias_variable([self.layers_encoder[i+1]], \n",
    "                                                      name=str('biases_enc_%02i' % i)))\n",
    "\n",
    "        # initialize weights and biases in decoding model\n",
    "        self.weights_dec = []\n",
    "        self.biases_dec = []\n",
    "        for i in range(self.num_layers_dec-1):\n",
    "            self.weights_dec.append(self.weight_variable([self.layers_decoder[i], \n",
    "                                                          self.layers_decoder[i+1]],\n",
    "                                                         name=str('weights_dec_%02i' % i)))\n",
    "            self.biases_dec.append(self.bias_variable([self.layers_decoder[i+1]], \n",
    "                                                      name=str('biases_dec_%02i' % i)))\n",
    "\n",
    "        # intialize weights for means and stds of stochastic layer\n",
    "        self.weights_mean = self.weight_variable( \n",
    "                                         [self.layers_encoder[-1], self.num_lvs],\n",
    "                                         name='weights_mean')\n",
    "        self.biases_mean = self.bias_variable([self.num_lvs], name='biases_mean')\n",
    "        self.weights_log_var = self.weight_variable( \n",
    "                                         [self.layers_encoder[-1], self.num_lvs],\n",
    "                                         name='weights_log_var')\n",
    "        self.biases_log_var = self.bias_variable([self.num_lvs], name='biases_log_var')\n",
    "        \n",
    "    def _define_recognition_network(self):\n",
    "        \"\"\" Create a recognition network to transform inputs into\n",
    "        its latent represenation\n",
    "        \"\"\"\n",
    "            \n",
    "        # push data through the encoding function to determine mean and std\n",
    "        # of latent vars\n",
    "        z_enc = [];\n",
    "        for i in range(self.num_layers_enc):\n",
    "            if i == 0:\n",
    "                z_enc.append(self.x);\n",
    "            else:\n",
    "                z_enc.append(self.act_func(tf.add( \n",
    "                             tf.matmul(z_enc[i-1], self.weights_enc[i-1]), \n",
    "                             self.biases_enc[i-1])))\n",
    "\n",
    "        # weights to estimate mean of normally distributed latent vars\n",
    "        self.z_mean = tf.add(tf.matmul(z_enc[-1], self.weights_mean), \n",
    "                             self.biases_mean)\n",
    "        # estimating log of the variance is easier since the latent loss has\n",
    "        # a log determinant term\n",
    "        self.z_log_var = tf.add(tf.matmul(z_enc[-1], self.weights_log_var), \n",
    "                                self.biases_log_var)\n",
    "\n",
    "    def _define_generator_network(self):\n",
    "        \"\"\" Create a generator network to transform a random sample\n",
    "        in the latent space into an image\n",
    "        \"\"\"\n",
    "                    \n",
    "        # transform estimated mean and log variance into a sampled value\n",
    "        # of the latent state using z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.mul(tf.sqrt(tf.exp(self.z_log_var)), self.eps))\n",
    "\n",
    "        # push data through the decoding function to reconstruct data\n",
    "        z_dec = [];\n",
    "        for i in range(self.num_layers_dec-1):\n",
    "            if i == 0:\n",
    "                z_dec.append(self.act_func(tf.add( \n",
    "                             tf.matmul(self.z, self.weights_dec[i]), \n",
    "                             self.biases_dec[i])))\n",
    "            else:\n",
    "                z_dec.append(self.act_func(tf.add( \n",
    "                             tf.matmul(z_dec[i-1], self.weights_dec[i]), \n",
    "                             self.biases_dec[i])))\n",
    "\n",
    "        # define this for easier access later\n",
    "        self.x_recon = z_dec[-1]\n",
    "\n",
    "    def _define_loss_optimizer(self):\n",
    "        \"\"\" Create the loss function that will be used to optimize\n",
    "        model parameters as well as define the optimizer\n",
    "        \"\"\"\n",
    "            \n",
    "        # define reconstruction loss\n",
    "        loss_recon = 0.5*tf.reduce_sum(tf.square(self.x_recon - self.x), 1)\n",
    "\n",
    "        # define latent loss\n",
    "        loss_latent = 0.5*tf.reduce_sum(tf.exp(self.z_log_var) \n",
    "                                        + tf.square(self.z_mean) \n",
    "                                        - 1 - self.z_log_var, 1)\n",
    "\n",
    "        # define cost\n",
    "        self.cost = tf.reduce_mean(loss_recon + loss_latent)\n",
    "\n",
    "        # define one step of the optimization routine\n",
    "        self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "        \n",
    "    def train(self, sess, batch_size=None, \n",
    "                          training_epochs=75, \n",
    "                          display_epochs=1):\n",
    "        \"\"\" Network training by specifying epochs \"\"\"\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "        \n",
    "            batch_size = self.batch_size if batch_size is None else batch_size \n",
    "\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                num_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "                for batch in range(num_batches):\n",
    "\n",
    "                    # get batch of data for this training step\n",
    "                    x = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                    # draw random samples for latent layer\n",
    "                    eps = np.random.normal(size=(self.batch_size, self.num_lvs))\n",
    "\n",
    "                    # one step of optimization routine\n",
    "                    sess.run(self.train_step, feed_dict={self.x: x[0], \n",
    "                                                         self.eps: eps})\n",
    "\n",
    "                # print training updates\n",
    "                if display_epochs is not None and epoch % display_epochs == 0:\n",
    "                    train_accuracy = sess.run(self.cost, feed_dict={self.x: x[0],\n",
    "                                                                    self.eps: eps})\n",
    "                    print(\"Epoch %03d: cost = %2.5f\" % (epoch, train_accuracy))\n",
    "                \n",
    "    def train_iters(self, sess, batch_size=None, \n",
    "                                training_iters=20000, \n",
    "                                display_iters=2000):\n",
    "        \"\"\" Network training by specifying number of iterations rather than epochs\n",
    "        Used for easily generating sample outputs during training\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = self.batch_size if batch_size is None else batch_size \n",
    "        \n",
    "        for tr_iter in range(training_iters):\n",
    "        \n",
    "            # get batch of data for this training step\n",
    "            x = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # draw random samples for latent layer\n",
    "            eps = np.random.normal(size=(self.batch_size, self.num_lvs))\n",
    "\n",
    "            # one step of optimization routine\n",
    "            sess.run(self.train_step, feed_dict={self.x: x[0], \n",
    "                                                 self.eps: eps})\n",
    "\n",
    "        # print training updates\n",
    "        if display_iters is not None and tr_iter % display_iters == 0:\n",
    "            train_accuracy = sess.run(self.cost, feed_dict={self.x: x[0],\n",
    "                                                            self.eps: eps})\n",
    "            print(\"Iter %03d: cost = %2.5f\" % (tr_iter, train_accuracy))\n",
    "        \n",
    "    def generate(self, sess, z_mean=None):\n",
    "        \"\"\" Sample the network and generate an image \n",
    "        \n",
    "        If z_mean is None, a random point is generated using the prior in\n",
    "        the latent space, else z_mean is used as the point in latent space\n",
    "        \"\"\"\n",
    "        \n",
    "        if z_mean is None:\n",
    "            z_mean = np.random.normal(size=self.num_lvs)\n",
    "            \n",
    "        return sess.run(self.x_recon, feed_dict={self.z: z_mean})\n",
    "        \n",
    "    def recognize(self, sess, x):\n",
    "        \"\"\" Transform a given input into its latent represenation \"\"\"\n",
    "        return sess.run(self.z_mean, feed_dict={self.x: x})\n",
    "        \n",
    "    def reconstruct(self, sess, x, eps):\n",
    "        \"\"\" Transform a given input into its reconstruction \"\"\"\n",
    "        return sess.run(self.x_recon, feed_dict={self.x: x, self.eps: eps})\n",
    "    \n",
    "    def save_model(self, sess, save_file=None):\n",
    "        \"\"\" Save model parameters \"\"\"\n",
    "        \n",
    "        assert save_file, 'Must specify filename to save model'\n",
    "        self.saver.save(sess, save_file)\n",
    "        print('Model saved to %s' % save_file)\n",
    "        \n",
    "    def load_model(self, sess, save_file=None):\n",
    "        \"\"\" Load previously saved model parameters \"\"\"\n",
    "        \n",
    "        assert save_file, 'Must specify model location'\n",
    "        self.saver.restore(sess, save_file)\n",
    "        print('Model loaded from %s' % save_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train a VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_file = 0\n",
    "\n",
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 100\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 100\n",
    "display_epochs = 5\n",
    "\n",
    "# initialize network\n",
    "vae = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder,\n",
    "          learning_rate=1e-3) \n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)\n",
    "        \n",
    "# train network\n",
    "vae.train(sess, batch_size=batch_size,\n",
    "                training_epochs=training_epochs,\n",
    "                display_epochs=display_epochs)\n",
    "\n",
    "# save network\n",
    "if save_file:\n",
    "    vae.save_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/vae-mnist.ckpt')\n",
    "\n",
    "# close the tensorflow session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload already trained model\n",
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 20\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 2\n",
    "display_epochs = 1\n",
    "\n",
    "# initialize network\n",
    "vae = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder)\n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# restore previously trained model\n",
    "vae.load_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/vae-mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = mnist.train.next_batch(vae.batch_size)\n",
    "eps = np.zeros((vae.batch_size, vae.num_lvs))\n",
    "recon = vae.reconstruct(sess, x[0], eps)\n",
    "\n",
    "f, ax = plt.subplots(2,5)\n",
    "for j in range(5):\n",
    "    ax[0,j].imshow(np.reshape(x[0][j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[0,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[0,j].axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax[1,j].imshow(np.reshape(recon[j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[1,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[1,j].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "canvas = np.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean = np.array([[xi, yi]])\n",
    "        x_mean = vae.generate(sess, z_mean=z_mean)\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))        \n",
    "Xi, Yi = np.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas, origin=\"upper\",\n",
    "           interpolation=\"nearest\",\n",
    "           cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIF Animation of Latent Space During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 2\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# initialize model\n",
    "vae = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training details\n",
    "batch_size = 100\n",
    "display_iters = None\n",
    "iters_per_image = np.logspace(0, 3, num=50).astype(int)\n",
    "\n",
    "# image details\n",
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "# store processed images\n",
    "dir_path = '/home/mattw/Desktop/test_movie'  \n",
    "saving = 1\n",
    "\n",
    "for epoch, iters in enumerate(iters_per_image):\n",
    "    \n",
    "    # output updates\n",
    "    print('\\rEpoch %03g of %03g - training for %05g iters' % \n",
    "          (epoch+1, iters_per_image.size, iters), end='')\n",
    "    \n",
    "    # train model\n",
    "    vae.train_iters(sess, batch_size=batch_size,\n",
    "                          training_iters=iters,\n",
    "                          display_iters=display_iters)\n",
    "    \n",
    "    # create latent state representation\n",
    "    canvas = np.empty((28*ny, 28*nx))\n",
    "    for i, yi in enumerate(x_values):\n",
    "        for j, xi in enumerate(y_values):\n",
    "            z_mean = np.array([[xi, yi]])\n",
    "            x_mean = vae.generate(sess, z_mean=z_mean)\n",
    "            canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "    \n",
    "    # save output\n",
    "    if saving:\n",
    "        file_name = 'vae-mnist_epoch_%03i.jpg' % epoch\n",
    "        file_path = '/'.join([dir_path, file_name])\n",
    "        canvas = np.uint8(255*canvas)\n",
    "        PIL.Image.fromarray(canvas).save(file_path, 'jpeg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to create a gif:\n",
    "convert -delay 4x120 -loop 0 *.jpg animated.gif\n",
    "\n",
    "take all jpgs in current directory and turn them into a gif that loops indefinitely, with a framerate of 120/4 = 30 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Matt Whiteway\" -d -v -m -p numpy,tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
