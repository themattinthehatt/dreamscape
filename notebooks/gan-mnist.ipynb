{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "______________________________________________________________________________________________________\n",
    "This notebook contains a simple generative adversarial network. \n",
    "\n",
    "The following resources have been helpful:\n",
    "* https://arxiv.org/pdf/1701.00160.pdf\n",
    "* http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/\n",
    "_______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets('data/mnist', one_hot=False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import models.GAN as gan\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define and Train a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'models.GAN' from '../models/GAN.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float argument required, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-121e2d4dfb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m net.train(sess, batch_size=batch_size,\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 display_epochs=display_epochs)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_elapsed: %g'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mattw/Dropbox/git/dreamscape/models/GAN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess, batch_size, training_epochs, display_epochs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                     print('Epoch %03d: disc cost = %2.5f' %\n\u001b[0;32m--> 225\u001b[0;31m                           (epoch, train_accuracy_disc))\n\u001b[0m\u001b[1;32m    226\u001b[0m                     print('Epoch %03d: gen cost = %2.5f' %\n\u001b[1;32m    227\u001b[0m                           (epoch, train_accuracy_gen))\n",
      "\u001b[0;31mTypeError\u001b[0m: float argument required, not NoneType"
     ]
    }
   ],
   "source": [
    "save_file = 0\n",
    "save_dir = '/media/data/Dropbox/Git/dreamscape/tmp/gan-mnist.ckpt'\n",
    "\n",
    "# define model params\n",
    "layers_generator = [200, 400, 784]\n",
    "layers_discriminator = [784, 400, 200, 1]\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 10\n",
    "display_epochs = 1\n",
    "use_gpu = 1\n",
    "\n",
    "# initialize network\n",
    "net = gan.GAN(layers_gen=layers_generator, \n",
    "              layers_disc=layers_discriminator,\n",
    "              learning_rate=1e-3)\n",
    "\n",
    "# start the tensorflow session\n",
    "config = tf.ConfigProto(device_count = {'GPU': use_gpu})\n",
    "sess = tf.Session(config=config, graph=net.graph)\n",
    "sess.run(net.init)\n",
    "\n",
    "# train network\n",
    "time_start = time.time()\n",
    "net.train(sess, batch_size=batch_size,\n",
    "                training_epochs=training_epochs,\n",
    "                display_epochs=display_epochs)\n",
    "time_end = time.time()\n",
    "print('time_elapsed: %g' % (time_end - time_start))\n",
    "\n",
    "# save network\n",
    "if save_file:\n",
    "    net.save_model(sess, save_dir)\n",
    "\n",
    "# close the tensorflow session\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reload already trained model\n",
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 20\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 2\n",
    "display_epochs = 1\n",
    "\n",
    "# initialize network\n",
    "vae = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder)\n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# restore previously trained model\n",
    "vae.load_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/vae-mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reconstruction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = mnist.train.next_batch(vae.batch_size)\n",
    "eps = np.zeros((vae.batch_size, vae.num_lvs))\n",
    "recon = vae.reconstruct(sess, x[0], eps)\n",
    "\n",
    "f, ax = plt.subplots(2,5)\n",
    "for j in range(5):\n",
    "    ax[0,j].imshow(np.reshape(x[0][j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[0,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[0,j].axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax[1,j].imshow(np.reshape(recon[j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[1,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[1,j].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Latent Space Visualization I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "canvas = np.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean = np.array([[xi, yi]])\n",
    "        x_mean = vae.generate(sess, z_mean=z_mean)\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))        \n",
    "Xi, Yi = np.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas, origin=\"upper\",\n",
    "           interpolation=\"nearest\",\n",
    "           cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## GIF Animation of Latent Space During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 2\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# initialize model\n",
    "vae = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# training details\n",
    "batch_size = 100\n",
    "display_iters = None\n",
    "iters_per_image = np.logspace(0, 3, num=50).astype(int)\n",
    "\n",
    "# image details\n",
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "# store processed images\n",
    "dir_path = '/home/mattw/Desktop/test_movie'  \n",
    "saving = 1\n",
    "\n",
    "for epoch, iters in enumerate(iters_per_image):\n",
    "    \n",
    "    # output updates\n",
    "    print('\\rEpoch %03g of %03g - training for %05g iters' % \n",
    "          (epoch+1, iters_per_image.size, iters), end='')\n",
    "    \n",
    "    # train model\n",
    "    vae.train_iters(sess, batch_size=batch_size,\n",
    "                          training_iters=iters,\n",
    "                          display_iters=display_iters)\n",
    "    \n",
    "    # create latent state representation\n",
    "    canvas = np.empty((28*ny, 28*nx))\n",
    "    for i, yi in enumerate(x_values):\n",
    "        for j, xi in enumerate(y_values):\n",
    "            z_mean = np.array([[xi, yi]])\n",
    "            x_mean = vae.generate(sess, z_mean=z_mean)\n",
    "            canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "    \n",
    "    # save output\n",
    "    if saving:\n",
    "        file_name = 'vae-mnist_epoch_%03i.jpg' % epoch\n",
    "        file_path = '/'.join([dir_path, file_name])\n",
    "        canvas = np.uint8(255*canvas)\n",
    "        PIL.Image.fromarray(canvas).save(file_path, 'jpeg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### to create a gif:\n",
    "convert -delay 4x120 -loop 0 *.jpg animated.gif\n",
    "\n",
    "take all jpgs in current directory and turn them into a gif that loops indefinitely, with a framerate of 120/4 = 30 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Matt Whiteway\" -d -v -m -p numpy,tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
