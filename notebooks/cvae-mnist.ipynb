{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________\n",
    "This notebook contains a simple conditional variational autoencoder. For now the conditioning is implemented by concatenating the one-hot classification labels to the input for the encoder, and to the latent variables for the decoder. Future work will allow for the ability to incorporate labels in a more general fashion.\n",
    "\n",
    "The following resources have been helpful:\n",
    "* https://arxiv.org/pdf/1606.05908v2.pdf\n",
    "* https://jmetzen.github.io/2015-11-27/vae.html\n",
    "_______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/mnist', one_hot=True)\n",
    "from __future__ import print_function\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVAE(object):\n",
    "    \"\"\" Conditional Variational Autoencoder class \"\"\"\n",
    "    \n",
    "    def __init__(self, layers_encoder=None, layer_latent=None, layers_decoder=None, \n",
    "                 num_categories=10, act_func=tf.nn.relu, batch_size=100, learning_rate=1e-3):\n",
    "        \"\"\" Constructor for VAE class \"\"\"\n",
    "        \n",
    "        assert layers_encoder, \"Must specify layer sizes for encoder\"\n",
    "        assert layer_latent, \"Must specify number of latent dimensions\"\n",
    "        assert layers_decoder, \"Must specify layer sizes for decoder\"\n",
    "        self.num_categories = num_categories\n",
    "        self.layers_encoder = layers_encoder\n",
    "        # concatenation of input and labels\n",
    "        self.layers_encoder[0] += self.num_categories\n",
    "        self.layer_latent = layer_latent\n",
    "        self.layers_decoder = layers_decoder\n",
    "        # concatenation of latent variables and labels\n",
    "        self.layers_decoder.insert(0, self.layer_latent + self.num_categories) # helps with weight init later\n",
    "        \n",
    "        self.act_func = act_func\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # define useful constants\n",
    "        self.num_lvs = self.layer_latent\n",
    "        self.num_layers_enc = len(self.layers_encoder)\n",
    "        self.num_layers_dec = len(self.layers_decoder)\n",
    "        \n",
    "        # for saving and restoring models\n",
    "        self.graph = tf.Graph() # must be initialized before graph creation\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            # create placeholders for input and random values\n",
    "            self.x = tf.placeholder(tf.float32, shape=[None, self.layers_encoder[0]-self.num_categories])\n",
    "            self.labels = tf.placeholder(tf.float32, shape=[None, self.num_categories])\n",
    "            self.eps = tf.placeholder(tf.float32, shape=[None, self.num_lvs])\n",
    "            \n",
    "            # initialize weights and create model\n",
    "            self._initialize_weights()\n",
    "            self._define_recognition_network()\n",
    "            self._define_generator_network()\n",
    "            self._define_loss_optimizer()\n",
    "        \n",
    "            # add additional ops\n",
    "            # for saving and restoring models\n",
    "            self.saver = tf.train.Saver() # must be initialized after var creation\n",
    "            # add variable initialization op to graph\n",
    "            self.init = tf.initialize_all_variables()\n",
    "            \n",
    "        \n",
    "    @staticmethod\n",
    "    def weight_variable(shape, name='None'):\n",
    "        \"\"\" Utility method to clean up initialization \"\"\"\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial, name=name)\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_variable(shape, name='None'):\n",
    "        \"\"\" Utility method to clean up initialization \"\"\"\n",
    "        initial = tf.constant(0.0, shape=shape)\n",
    "        return tf.Variable(initial, name=name)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\" Initialize weights and biases in model \"\"\"\n",
    "\n",
    "        # initialize weights and biases in encoding model\n",
    "        self.weights_enc = []\n",
    "        self.biases_enc = []\n",
    "        for i in range(self.num_layers_enc-1):\n",
    "            self.weights_enc.append(self.weight_variable([self.layers_encoder[i], \n",
    "                                                          self.layers_encoder[i+1]],\n",
    "                                                         name=str('weights_enc_%02i' % i)))\n",
    "            self.biases_enc.append(self.bias_variable([self.layers_encoder[i+1]], \n",
    "                                                      name=str('biases_enc_%02i' % i)))\n",
    "\n",
    "        # initialize weights and biases in decoding model\n",
    "        self.weights_dec = []\n",
    "        self.biases_dec = []\n",
    "        for i in range(self.num_layers_dec-1):\n",
    "            self.weights_dec.append(self.weight_variable([self.layers_decoder[i], \n",
    "                                                          self.layers_decoder[i+1]],\n",
    "                                                         name=str('weights_dec_%02i' % i)))\n",
    "            self.biases_dec.append(self.bias_variable([self.layers_decoder[i+1]], \n",
    "                                                      name=str('biases_dec_%02i' % i)))\n",
    "\n",
    "        # intialize weights for means and stds of stochastic layer\n",
    "        self.weights_mean = self.weight_variable( \n",
    "                                         [self.layers_encoder[-1], self.num_lvs],\n",
    "                                         name='weights_mean')\n",
    "        self.biases_mean = self.bias_variable([self.num_lvs], name='biases_mean')\n",
    "        self.weights_log_var = self.weight_variable( \n",
    "                                         [self.layers_encoder[-1], self.num_lvs],\n",
    "                                         name='weights_log_var')\n",
    "        self.biases_log_var = self.bias_variable([self.num_lvs], name='biases_log_var')\n",
    "        \n",
    "    def _define_recognition_network(self):\n",
    "        \"\"\" Create a recognition network to transform inputs into\n",
    "        its latent represenation\n",
    "        \"\"\"\n",
    "            \n",
    "        # push data through the encoding function to determine mean and std\n",
    "        # of latent vars\n",
    "        z_enc = [];\n",
    "        for i in range(self.num_layers_enc):\n",
    "            if i == 0:\n",
    "                z_enc.append(tf.concat(1, [self.x, self.labels]))\n",
    "            else:\n",
    "                z_enc.append(self.act_func(tf.add( \n",
    "                             tf.matmul(z_enc[i-1], self.weights_enc[i-1]), \n",
    "                             self.biases_enc[i-1])))\n",
    "\n",
    "        # weights to estimate mean of normally distributed latent vars\n",
    "        self.z_mean = tf.add(tf.matmul(z_enc[-1], self.weights_mean), \n",
    "                             self.biases_mean)\n",
    "        # estimating log of the variance is easier since the latent loss has\n",
    "        # a log determinant term\n",
    "        self.z_log_var = tf.add(tf.matmul(z_enc[-1], self.weights_log_var), \n",
    "                                self.biases_log_var)\n",
    "\n",
    "    def _define_generator_network(self):\n",
    "        \"\"\" Create a generator network to transform a random sample\n",
    "        in the latent space into an image\n",
    "        \"\"\"\n",
    "            \n",
    "        # transform estimated mean and log variance into a sampled value\n",
    "        # of the latent state using z = mu + sigma*epsilon\n",
    "        self.z = tf.add(self.z_mean, \n",
    "                        tf.mul(tf.sqrt(tf.exp(self.z_log_var)), self.eps))\n",
    "\n",
    "        # push data through the decoding function to reconstruct data\n",
    "        z_dec = [];\n",
    "        for i in range(self.num_layers_dec-1):\n",
    "            if i == 0:\n",
    "                z_dec.append(self.act_func(tf.add( \n",
    "                             tf.matmul(tf.concat(1, [self.z, self.labels]), self.weights_dec[i]), \n",
    "                             self.biases_dec[i])))\n",
    "            else:\n",
    "                z_dec.append(self.act_func(tf.add( \n",
    "                             tf.matmul(z_dec[i-1], self.weights_dec[i]), \n",
    "                             self.biases_dec[i])))\n",
    "\n",
    "        # define this for easier access later\n",
    "        self.x_recon = z_dec[-1]\n",
    "\n",
    "    def _define_loss_optimizer(self):\n",
    "        \"\"\" Create the loss function that will be used to optimize\n",
    "        model parameters as well as define the optimizer\n",
    "        \"\"\"\n",
    "            \n",
    "        # define reconstruction loss\n",
    "        loss_recon = 0.5*tf.reduce_sum(tf.square(self.x_recon - self.x), 1)\n",
    "\n",
    "        # define latent loss\n",
    "        loss_latent = 0.5*tf.reduce_sum(tf.exp(self.z_log_var) \n",
    "                                        + tf.square(self.z_mean) \n",
    "                                        - 1 - self.z_log_var, 1)\n",
    "\n",
    "        # define cost\n",
    "        self.cost = tf.reduce_mean(loss_recon + loss_latent)\n",
    "\n",
    "        # define one step of the optimization routine\n",
    "        self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "            \n",
    "        \n",
    "    def train(self, sess, batch_size=None, \n",
    "                          training_epochs=75, \n",
    "                          display_epochs=1):\n",
    "        \"\"\" Network training by specifying epochs \"\"\"\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "        \n",
    "            batch_size = self.batch_size if batch_size is None else batch_size \n",
    "\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                num_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "                for batch in range(num_batches):\n",
    "\n",
    "                    # get batch of data for this training step\n",
    "                    x = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                    # draw random samples for latent layer\n",
    "                    eps = np.random.normal(size=(self.batch_size, self.num_lvs))\n",
    "\n",
    "                    # one step of optimization routine\n",
    "                    sess.run(self.train_step, feed_dict={self.x: x[0], \n",
    "                                                         self.labels: x[1],\n",
    "                                                         self.eps: eps})\n",
    "\n",
    "                # print training updates\n",
    "                if display_epochs is not None and epoch % display_epochs == 0:\n",
    "                    train_accuracy = sess.run(self.cost, feed_dict={self.x: x[0],\n",
    "                                                                    self.labels: x[1], \n",
    "                                                                    self.eps: eps})\n",
    "                    print(\"Epoch %03d: cost = %2.5f\" % (epoch, train_accuracy))\n",
    "                \n",
    "    def train_iters(self, sess, batch_size=None, \n",
    "                                training_iters=20000, \n",
    "                                display_iters=2000):\n",
    "        \"\"\" Network training by specifying number of iterations rather than epochs\n",
    "        Used for easily generating sample outputs during training\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = self.batch_size if batch_size is None else batch_size \n",
    "        \n",
    "        for tr_iter in range(training_iters):\n",
    "        \n",
    "            # get batch of data for this training step\n",
    "            x = mnist.train.next_batch(batch_size)\n",
    "\n",
    "            # draw random samples for latent layer\n",
    "            eps = np.random.normal(size=(self.batch_size, self.num_lvs))\n",
    "\n",
    "            # one step of optimization routine\n",
    "            sess.run(self.train_step, feed_dict={self.x: x[0],\n",
    "                                                 self.labels: x[1],\n",
    "                                                 self.eps: eps})\n",
    "\n",
    "        # print training updates\n",
    "        if display_iters is not None and tr_iter % display_iters == 0:\n",
    "            train_accuracy = sess.run(self.cost, feed_dict={self.x: x[0],\n",
    "                                                            self.labels: x[1],\n",
    "                                                            self.eps: eps})\n",
    "            print(\"Iter %03d: cost = %2.5f\" % (tr_iter, train_accuracy))\n",
    "        \n",
    "    def generate(self, sess, z_mean=None, label=None):\n",
    "        \"\"\" Sample the network and generate an image \n",
    "        \n",
    "        If z_mean is None, a random point is generated using the prior in\n",
    "        the latent space, else z_mean is used as the point in latent space\n",
    "        \n",
    "        If label is None, a random label is generated using a uniform \n",
    "        distribution over the categories, else label should be an integer\n",
    "        that will be converted into a one-hot representation if not already\n",
    "        \"\"\"\n",
    "        \n",
    "        if z_mean is None:\n",
    "            z_mean = np.random.normal(size=self.num_lvs)\n",
    "                             \n",
    "        if label is None:\n",
    "            pos = int(np.floor(np.random.uniform(low=0.0, high=self.num_categories)))\n",
    "            label = np.zeros(shape=(1,self.num_categories))\n",
    "            label[:,pos] = 1\n",
    "        elif len(label.shape) == 1:\n",
    "            pos = label\n",
    "            label = np.zeros(shape=(1,self.num_categories))\n",
    "            label[:,pos] = 1\n",
    "            \n",
    "        return sess.run(self.x_recon, feed_dict={self.z: z_mean, self.labels: label})\n",
    "        \n",
    "    def recognize(self, sess, x, label):\n",
    "        \"\"\" Transform a given input into its latent represenation \n",
    "        \n",
    "        label should be an integer that will be converted into a one-hot representation\n",
    "        if not already in that format\n",
    "        \"\"\"\n",
    "                             \n",
    "        if len(label.shape) == 1:\n",
    "            pos = label\n",
    "            label = np.zeros(shape=(1,self.num_categories))\n",
    "            label[:,pos] = 1\n",
    "        \n",
    "        return sess.run(self.z_mean, feed_dict={self.x: x, self.labels: label})\n",
    "        \n",
    "    def reconstruct(self, sess, x, label, eps):\n",
    "        \"\"\" Transform a given input into its reconstruction \n",
    "        \n",
    "        label should be an integer that will be converted into a one-hot representation\n",
    "        if not already in that format\n",
    "        \"\"\"\n",
    "           \n",
    "        if len(label.shape) == 1:\n",
    "            pos = label\n",
    "            label = np.zeros(shape=(1,self.num_categories))\n",
    "            label[:pos] = 1\n",
    "                             \n",
    "        return sess.run(self.x_recon, feed_dict={self.x: x, self.labels: label, self.eps: eps})\n",
    "    \n",
    "    def save_model(self, sess, save_file=None):\n",
    "        \"\"\" Save model parameters \"\"\"\n",
    "        \n",
    "        assert save_file, 'Must specify filename to save model'\n",
    "        self.saver.save(sess, save_file)\n",
    "        print('Model saved to %s' % save_file)\n",
    "        \n",
    "    def load_model(self, sess, save_file=None):\n",
    "        \"\"\" Load previously saved model parameters \"\"\"\n",
    "        \n",
    "        assert save_file, 'Must specify model location'\n",
    "        self.saver.restore(sess, save_file)\n",
    "        print('Model loaded from %s' % save_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train a CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: cost = 22.54309\n",
      "Epoch 005: cost = 18.81212\n",
      "Epoch 010: cost = 18.25508\n",
      "Epoch 015: cost = 18.59010\n",
      "Epoch 020: cost = 17.93069\n",
      "Epoch 025: cost = 16.66950\n"
     ]
    }
   ],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 5\n",
    "layers_decoder = [400, 400, 784]\n",
    "num_categories = 10\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 30\n",
    "display_epochs = 5\n",
    "\n",
    "# initialize network\n",
    "vae = CVAE(layers_encoder=layers_encoder, \n",
    "           layer_latent=layer_latent,\n",
    "           layers_decoder=layers_decoder,\n",
    "           num_categories=num_categories,\n",
    "           learning_rate=1e-4) \n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)\n",
    "        \n",
    "# train network\n",
    "vae.train(sess, batch_size=batch_size,\n",
    "                training_epochs=training_epochs,\n",
    "                display_epochs=display_epochs)\n",
    "\n",
    "# save network\n",
    "# vae.save_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/cvae-mnist.ckpt')\n",
    "\n",
    "# close the tensorflow session\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 20\n",
    "layers_decoder = [400, 400, 784]\n",
    "num_categories=10\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 2\n",
    "display_epochs = 1\n",
    "\n",
    "# initialize network\n",
    "vae = CVAE(layers_encoder=layers_encoder, \n",
    "           layer_latent=layer_latent,\n",
    "           layers_decoder=layers_decoder,\n",
    "           num_categories=num_categories)\n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)\n",
    "\n",
    "# restore previously trained model\n",
    "vae.load_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/cvae-mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = mnist.train.next_batch(vae.batch_size)\n",
    "eps = np.zeros((vae.batch_size, vae.num_lvs))\n",
    "recon = vae.reconstruct(sess, x[0], x[1], eps)\n",
    "\n",
    "f, ax = plt.subplots(2,5)\n",
    "for j in range(5):\n",
    "    ax[0,j].imshow(np.reshape(x[0][j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[0,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[0,j].axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax[1,j].imshow(np.reshape(recon[j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[1,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[1,j].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization I - 2 LVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 2) for Tensor u'Add_4:0', which has shape '(?, 5)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-cb2596bbaf03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mcanvas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-23644573f761>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, sess, z_mean, label)\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_recon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 710\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    711\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 887\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    888\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 2) for Tensor u'Add_4:0', which has shape '(?, 5)'"
     ]
    }
   ],
   "source": [
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "canvas = np.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean = np.array([[xi, yi]])\n",
    "        x_mean = vae.generate(sess, z_mean=z_mean, label=np.array([4]))\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))        \n",
    "Xi, Yi = np.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas, origin=\"upper\",\n",
    "           interpolation=\"nearest\",\n",
    "           cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualization I - >2 LVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lv_dims = np.array([0, 4])\n",
    "\n",
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "z_mean = np.random.normal(size=(1,vae.num_lvs))\n",
    "\n",
    "canvas = np.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean[0,lv_dims[0]] = xi\n",
    "        z_mean[0,lv_dims[1]] = yi\n",
    "        x_mean = vae.generate(sess, z_mean=z_mean, label=np.array([9]))\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))        \n",
    "Xi, Yi = np.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas, origin=\"upper\",\n",
    "           interpolation=\"nearest\",\n",
    "           cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable          Type                   Data/Info\n",
      "--------------------------------------------------\n",
      "CVAE              type                   <class '__main__.CVAE'>\n",
      "Xi                ndarray                20x20: 400 elems, type `float64`, 3200 bytes\n",
      "Yi                ndarray                20x20: 400 elems, type `float64`, 3200 bytes\n",
      "ax                ndarray                2x5: 10 elems, type `object`, 80 bytes\n",
      "batch_size        int                    100\n",
      "canvas            ndarray                560x560: 313600 elems, type `float64`, 2508800 bytes (2 Mb)\n",
      "cost              float32                14.2701\n",
      "display_epochs    int                    5\n",
      "eps               ndarray                100x5: 500 elems, type `float64`, 4000 bytes\n",
      "f                 Figure                 Figure(640x480)\n",
      "i                 int                    0\n",
      "input_data        module                 <module 'tensorflow.examp<...>ls/mnist/input_data.pyc'>\n",
      "j                 int                    0\n",
      "layer_latent      int                    5\n",
      "layers_decoder    list                   n=4\n",
      "layers_encoder    list                   n=3\n",
      "lv_dims           list                   n=2\n",
      "mnist             Datasets               Datasets(train=<tensorflo<...>bject at 0x7f8f2c071c10>)\n",
      "np                module                 <module 'numpy' from '/us<...>ages/numpy/__init__.pyc'>\n",
      "num_categories    int                    10\n",
      "nx                int                    20\n",
      "ny                int                    20\n",
      "plt               module                 <module 'matplotlib.pyplo<...>s/matplotlib/pyplot.pyc'>\n",
      "print_function    __future__._Feature    _Feature((2, 6, 0, 'alpha<...>0, 0, 'alpha', 0), 65536)\n",
      "recon             ndarray                100x784: 78400 elems, type `float32`, 313600 bytes (306 kb)\n",
      "sess              Session                <tensorflow.python.client<...>object at 0x7f8f3c8c9590>\n",
      "tf                module                 <module 'tensorflow' from<...>tensorflow/__init__.pyc'>\n",
      "training_epochs   int                    30\n",
      "vae               CVAE                   <__main__.CVAE object at 0x7f8f3c8c9210>\n",
      "x                 tuple                  n=2\n",
      "x_mean            ndarray                1x784: 784 elems, type `float32`, 3136 bytes\n",
      "x_values          ndarray                20: 20 elems, type `float64`, 160 bytes\n",
      "xi                float64                -3.0\n",
      "y_values          ndarray                20: 20 elems, type `float64`, 160 bytes\n",
      "yi                float64                -3.0\n",
      "z_mean            ndarray                1x5: 5 elems, type `float64`, 40 bytes\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIF Animation of Latent Space During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 2\n",
    "layers_decoder = [400, 400, 784]\n",
    "num_categories = 10\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 2\n",
    "display_epochs = 1\n",
    "\n",
    "# initialize network\n",
    "vae = CVAE(layers_encoder=layers_encoder, \n",
    "           layer_latent=layer_latent,\n",
    "           layers_decoder=layers_decoder,\n",
    "           num_categories=num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 of 050 - training for 01000 iters"
     ]
    }
   ],
   "source": [
    "# training details\n",
    "batch_size = 100\n",
    "display_iters = None\n",
    "iters_per_image = np.logspace(0, 3, num=50).astype(int)\n",
    "\n",
    "# image details\n",
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "# store processed images\n",
    "dir_path = '/home/mattw/Desktop/test_movie'  \n",
    "saving = 1\n",
    "\n",
    "# start the tensorflow session\n",
    "sess = tf.Session(graph=vae.graph)\n",
    "sess.run(vae.init)\n",
    "\n",
    "for epoch, iters in enumerate(iters_per_image):\n",
    "\n",
    "    # output updates\n",
    "    print('\\rEpoch %03g of %03g - training for %05g iters' % \n",
    "          (epoch+1, iters_per_image.size, iters), end='')\n",
    "\n",
    "    # train model\n",
    "    vae.train_iters(sess, batch_size=batch_size,\n",
    "                          training_iters=iters,\n",
    "                          display_iters=display_iters)\n",
    "\n",
    "    # create latent state representation\n",
    "    canvas = np.empty((28*ny, 28*nx))\n",
    "    for i, yi in enumerate(x_values):\n",
    "        for j, xi in enumerate(y_values):\n",
    "            z_mean = np.array([[xi, yi]])\n",
    "            x_mean = vae.generate(sess, z_mean=z_mean, label=np.array([2]))\n",
    "            canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "    # save output\n",
    "    if saving:\n",
    "        file_name = 'vae-mnist_epoch_%03i.jpg' % epoch\n",
    "        file_path = '/'.join([dir_path, file_name])\n",
    "        canvas = np.uint8(255*canvas)\n",
    "        PIL.Image.fromarray(canvas).save(file_path, 'jpeg')\n",
    "\n",
    "# close tensorflow session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to create a gif:\n",
    "convert -delay 4x120 -loop 0 *.jpg animated.gif\n",
    "\n",
    "take all jpgs in current directory and turn them into a gif that loops indefinitely, with a framerate of 120/4 = 30 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matt Whiteway 2017-03-15 \n",
      "\n",
      "CPython 2.7.12\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.12.0\n",
      "tensorflow 0.10.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.4.0-66-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Matt Whiteway\" -d -v -m -p numpy,tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
