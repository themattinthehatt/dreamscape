{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "______________________________________________________________________________________________________\n",
    "This notebook contains a simple variational autoencoder. \n",
    "\n",
    "The following resources have been helpful:\n",
    "* https://arxiv.org/pdf/1606.05908v2.pdf\n",
    "* https://jmetzen.github.io/2015-11-27/vae.html\n",
    "_______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.VAE import VAE\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define and Train a VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/mattw/Dropbox/git/dreamscape/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch 000: cost = 25.97730\n",
      "Epoch 001: cost = 23.46889\n",
      "Epoch 002: cost = 23.69188\n",
      "Epoch 003: cost = 23.87182\n",
      "Epoch 004: cost = 22.17753\n",
      "Epoch 005: cost = 22.97959\n",
      "Epoch 006: cost = 22.44517\n",
      "Epoch 007: cost = 22.35687\n",
      "Epoch 008: cost = 23.78796\n",
      "Epoch 009: cost = 22.93682\n",
      "Epoch 010: cost = 22.09399\n",
      "Epoch 011: cost = 22.34856\n",
      "Epoch 012: cost = 22.61357\n",
      "Epoch 013: cost = 22.47763\n",
      "Epoch 014: cost = 21.57585\n",
      "Epoch 015: cost = 21.08847\n",
      "Epoch 016: cost = 21.63128\n",
      "Epoch 017: cost = 21.00709\n",
      "Epoch 018: cost = 22.09277\n",
      "Epoch 019: cost = 21.76694\n",
      "Epoch 020: cost = 21.69411\n",
      "Epoch 021: cost = 20.54572\n",
      "Epoch 022: cost = 21.49102\n",
      "Epoch 023: cost = 20.85258\n",
      "Epoch 024: cost = 21.72997\n",
      "Epoch 025: cost = 20.89057\n",
      "Epoch 026: cost = 20.27471\n",
      "Epoch 027: cost = 22.01970\n",
      "Epoch 028: cost = 20.64024\n",
      "Epoch 029: cost = 20.99042\n",
      "Epoch 030: cost = 21.77499\n",
      "Epoch 031: cost = 20.93375\n",
      "Epoch 032: cost = 21.44818\n",
      "Epoch 033: cost = 20.77491\n",
      "Epoch 034: cost = 21.48413\n",
      "Epoch 035: cost = 20.56929\n",
      "Epoch 036: cost = 21.61634\n",
      "Epoch 037: cost = 21.77073\n",
      "Epoch 038: cost = 20.11500\n",
      "Epoch 039: cost = 20.20034\n",
      "time_elapsed: 142.705\n"
     ]
    }
   ],
   "source": [
    "save_file = 0\n",
    "save_dir = '/media/data/Dropbox/Git/dreamscape/tmp/vae-mnist.ckpt'\n",
    "net_type = 'vae' # 'vae' | 'cvae'\n",
    "\n",
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 20\n",
    "layers_decoder = [400, 400, 784]\n",
    "num_categories = 10\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 40\n",
    "display_epochs = 1\n",
    "use_gpu = 1\n",
    "\n",
    "# initialize network\n",
    "if net_type is 'vae':\n",
    "    net = VAE(layers_encoder=layers_encoder, \n",
    "              layer_latent=layer_latent,\n",
    "              layers_decoder=layers_decoder,\n",
    "              learning_rate=1e-3,\n",
    "              data_dir='/home/mattw/Dropbox/git/dreamscape/data/',\n",
    "              data_type='mnist')\n",
    "elif net_type is 'cvae':\n",
    "    net = CVAE(layers_encoder=layers_encoder, \n",
    "              layer_latent=layer_latent,\n",
    "              layers_decoder=layers_decoder,\n",
    "              num_categories=num_categories,\n",
    "              learning_rate=1e-3,\n",
    "              data_dir='/home/mattw/Dropbox/git/dreamscape/data/',\n",
    "              data_type='mnist')\n",
    "\n",
    "# start the tensorflow session\n",
    "config = tf.ConfigProto(device_count = {'GPU': use_gpu})\n",
    "sess = tf.Session(config=config, graph=net.graph)\n",
    "sess.run(net.init)\n",
    "\n",
    "# train network\n",
    "time_start = time.time()\n",
    "net.train(sess, batch_size=batch_size,\n",
    "                training_epochs=training_epochs,\n",
    "                display_epochs=display_epochs)\n",
    "time_end = time.time()\n",
    "print('time_elapsed: %g' % (time_end - time_start))\n",
    "\n",
    "# save network\n",
    "if save_file:\n",
    "    net.save_model(sess, save_dir)\n",
    "\n",
    "# close the tensorflow session\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 20\n",
    "layers_decoder = [400, 400, 784]\n",
    "num_categories = 10\n",
    "\n",
    "# define training params\n",
    "batch_size = 100\n",
    "training_epochs = 40\n",
    "display_epochs = 1\n",
    "use_gpu = 1\n",
    "\n",
    "# initialize network\n",
    "if net_type is 'vae':\n",
    "    net = VAE(layers_encoder=layers_encoder, \n",
    "              layer_latent=layer_latent,\n",
    "              layers_decoder=layers_decoder,\n",
    "              learning_rate=1e-3,\n",
    "              data_dir='/home/mattw/Dropbox/git/dreamscape/data/',\n",
    "              data_type='mnist')\n",
    "elif net_type is 'cvae':\n",
    "    net = CVAE(layers_encoder=layers_encoder, \n",
    "              layer_latent=layer_latent,\n",
    "              layers_decoder=layers_decoder,\n",
    "              num_categories=num_categories,\n",
    "              learning_rate=1e-3,\n",
    "              data_dir='/home/mattw/Dropbox/git/dreamscape/data/',\n",
    "              data_type='mnist')\n",
    "\n",
    "# start the tensorflow session\n",
    "config = tf.ConfigProto(device_count = {'GPU': use_gpu})\n",
    "sess = tf.Session(config=config, graph=net.graph)\n",
    "sess.run(net.init)\n",
    "\n",
    "# restore previously trained model\n",
    "net.load_model(sess, '/media/data/Dropbox/Git/dreamscape/tmp/vae-mnist.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Visualize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reconstruction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = net.data.train.next_batch(net.batch_size)\n",
    "eps = np.zeros((net.batch_size, net.num_lvs))\n",
    "recon = net.reconstruct(sess, x[0], eps)\n",
    "\n",
    "f, ax = plt.subplots(2,5)\n",
    "for j in range(5):\n",
    "    ax[0,j].imshow(np.reshape(x[0][j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[0,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[0,j].axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax[1,j].imshow(np.reshape(recon[j,:], (28, 28)),\n",
    "                  interpolation=\"nearest\",\n",
    "                  cmap=\"gray\")\n",
    "    ax[1,j].axes.get_xaxis().set_visible(False)\n",
    "    ax[1,j].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Latent Space Visualization I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "canvas = np.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        z_mean = np.array([[xi, yi]])\n",
    "        x_mean = net.generate(sess, z_mean=z_mean)\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))        \n",
    "Xi, Yi = np.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas, origin=\"upper\",\n",
    "           interpolation=\"nearest\",\n",
    "           cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## GIF Animation of Latent Space During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define model params\n",
    "layers_encoder = [784, 400, 400]\n",
    "layer_latent = 2\n",
    "layers_decoder = [400, 400, 784]\n",
    "\n",
    "# initialize model\n",
    "net = VAE(layers_encoder=layers_encoder, \n",
    "          layer_latent=layer_latent,\n",
    "          layers_decoder=layers_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# training details\n",
    "batch_size = 100\n",
    "display_iters = None\n",
    "iters_per_image = np.logspace(0, 3, num=50).astype(int)\n",
    "\n",
    "# image details\n",
    "nx = ny = 20\n",
    "x_values = np.linspace(-3, 3, nx)\n",
    "y_values = np.linspace(-3, 3, ny)\n",
    "\n",
    "# store processed images\n",
    "dir_path = '/home/mattw/Desktop/test_movie'  \n",
    "saving = 1\n",
    "\n",
    "for epoch, iters in enumerate(iters_per_image):\n",
    "    \n",
    "    # output updates\n",
    "    print('\\rEpoch %03g of %03g - training for %05g iters' % \n",
    "          (epoch+1, iters_per_image.size, iters), end='')\n",
    "    \n",
    "    # train model\n",
    "    net.train_iters(sess, batch_size=batch_size,\n",
    "                          training_iters=iters,\n",
    "                          display_iters=display_iters)\n",
    "    \n",
    "    # create latent state representation\n",
    "    canvas = np.empty((28*ny, 28*nx))\n",
    "    for i, yi in enumerate(x_values):\n",
    "        for j, xi in enumerate(y_values):\n",
    "            z_mean = np.array([[xi, yi]])\n",
    "            x_mean = net.generate(sess, z_mean=z_mean)\n",
    "            canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
    "    \n",
    "    # save output\n",
    "    if saving:\n",
    "        file_name = 'vae-mnist_epoch_%03i.jpg' % epoch\n",
    "        file_path = '/'.join([dir_path, file_name])\n",
    "        canvas = np.uint8(255*canvas)\n",
    "        PIL.Image.fromarray(canvas).save(file_path, 'jpeg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### to create a gif:\n",
    "convert -delay 4x120 -loop 0 *.jpg animated.gif\n",
    "\n",
    "take all jpgs in current directory and turn them into a gif that loops indefinitely, with a framerate of 120/4 = 30 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matt Whiteway 2017-04-10 \n",
      "\n",
      "CPython 2.7.12\n",
      "IPython 4.2.0\n",
      "\n",
      "numpy 1.12.0\n",
      "tensorflow 0.10.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.4.0-72-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -a \"Matt Whiteway\" -d -v -m -p numpy,tensorflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
